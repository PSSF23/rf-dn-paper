{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "elder-pleasure",
   "metadata": {},
   "source": [
    "Urbansound8k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "equipped-parade",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "import IPython as IP\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pickle\n",
    "from include import helpers\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "from datetime import datetime\n",
    "from include import helpers\n",
    "\n",
    "from keras import backend as keras_backend\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, SpatialDropout2D, Activation, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D, LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint \n",
    "from keras.regularizers import l2\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "collective-clause",
   "metadata": {},
   "outputs": [],
   "source": [
    "us8k_path = os.path.abspath('./UrbanSound8K')\n",
    "audio_path = os.path.join(us8k_path, 'audio')\n",
    "metadata_path = os.path.join(us8k_path, 'metadata/UrbanSound8K.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "opponent-stopping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100032-3-0-0.wav</td>\n",
       "      <td>100032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.317551</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100263-2-0-117.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>58.5</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100263-2-0-121.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>60.5</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100263-2-0-126.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>63.0</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100263-2-0-137.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>68.5</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n",
       "0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n",
       "1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n",
       "2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n",
       "3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n",
       "4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n",
       "\n",
       "              class  \n",
       "0          dog_bark  \n",
       "1  children_playing  \n",
       "2  children_playing  \n",
       "3  children_playing  \n",
       "4  children_playing  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the metadata from the generated CSV\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fiscal-amplifier",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 501/8732\n",
      "Status: 1001/8732\n",
      "Status: 1501/8732\n",
      "Status: 2001/8732\n",
      "Status: 2501/8732\n",
      "Status: 3001/8732\n",
      "Status: 3501/8732\n",
      "Status: 4001/8732\n",
      "Status: 4501/8732\n",
      "Status: 5001/8732\n",
      "Status: 5501/8732\n",
      "Status: 6001/8732\n",
      "Status: 6501/8732\n",
      "Status: 7001/8732\n",
      "Status: 7501/8732\n",
      "Status: 8001/8732\n",
      "Status: 8501/8732\n",
      "Finished: 8731/8732\n"
     ]
    }
   ],
   "source": [
    "# Iterate through all audio files and extract MFCC\n",
    "features = []\n",
    "labels = []\n",
    "frames_max = 0\n",
    "counter = 0\n",
    "total_samples = len(metadata)\n",
    "n_mfcc = 40\n",
    "\n",
    "for index, row in metadata.iterrows():\n",
    "    file_path = os.path.join(os.path.abspath(audio_path), 'fold' + str(row[\"fold\"]), str(row[\"slice_file_name\"]))\n",
    "    class_label = row[\"class\"]\n",
    "\n",
    "    # Extract MFCCs (do not add padding)\n",
    "    mfccs = helpers.get_mfcc(file_path, 0, n_mfcc)\n",
    "    \n",
    "    # Save current frame count\n",
    "    num_frames = mfccs.shape[1]\n",
    "    \n",
    "    # Add row (feature / label)\n",
    "    features.append(mfccs)\n",
    "    labels.append(class_label)\n",
    "\n",
    "    # Update frames maximum\n",
    "    if (num_frames > frames_max):\n",
    "        frames_max = num_frames\n",
    "\n",
    "    # Notify update every N files\n",
    "    if (counter == 500):\n",
    "        print(\"Status: {}/{}\".format(index+1, total_samples))\n",
    "        counter = 0\n",
    "\n",
    "    counter += 1\n",
    "    \n",
    "print(\"Finished: {}/{}\".format(index, total_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "seventh-jenny",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add padding to features with less than frames than frames_max\n",
    "padded_features = helpers.add_padding(features, frames_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "painful-worship",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert features (X) and labels (y) to Numpy arrays\n",
    "X = np.array(padded_features)\n",
    "y = np.array(labels)\n",
    "\n",
    "# Optionally save the features to disk\n",
    "np.save(\"data/X-mfcc\", X)\n",
    "np.save(\"data/y-mfcc\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-howard",
   "metadata": {},
   "source": [
    "# Iterate through all audio files and extract MFCC\n",
    "features = []\n",
    "labels = []\n",
    "frames_max = 0\n",
    "counter = 0\n",
    "total_samples = len(metadata)\n",
    "n_mels=40\n",
    "\n",
    "for index, row in metadata.iterrows():\n",
    "    file_path = os.path.join(os.path.abspath(audio_path), 'fold' + str(row[\"fold\"]), str(row[\"slice_file_name\"]))\n",
    "    class_label = row[\"class\"]\n",
    "\n",
    "    # Extract Log-Mel Spectrograms (do not add padding)\n",
    "    mels = helpers.get_mel_spectrogram(file_path, 0, n_mels=n_mels)\n",
    "    \n",
    "    # Save current frame count\n",
    "    num_frames = mels.shape[1]\n",
    "    \n",
    "    # Add row (feature / label)\n",
    "    features.append(mels)\n",
    "    labels.append(class_label)\n",
    "\n",
    "    # Update frames maximum\n",
    "    if (num_frames > frames_max):\n",
    "        frames_max = num_frames\n",
    "\n",
    "    # Notify update every N files\n",
    "    if (counter == 500):\n",
    "        print(\"Status: {}/{}\".format(index+1, total_samples))\n",
    "        counter = 0\n",
    "\n",
    "    counter += 1\n",
    "    \n",
    "print(\"Finished: {}/{}\".format(index, total_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominican-polls",
   "metadata": {},
   "source": [
    "# Add padding to features with less than frames than frames_max\n",
    "padded_features = helpers.add_padding(features, frames_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-sunday",
   "metadata": {},
   "source": [
    "# Convert features (X) and labels (y) to Numpy arrays\n",
    "X = np.array(padded_features)\n",
    "y = np.array(labels)\n",
    "\n",
    "np.save(\"data/X-mel_spec\", X)\n",
    "np.save(\"data/y-mel_spec\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "national-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define general variables\n",
    "\n",
    "# Set your path to the dataset\n",
    "models_path = os.path.abspath('./models')\n",
    "data_path = os.path.abspath('./data')\n",
    "\n",
    "# Ensure \"channel last\" data format on Keras\n",
    "keras_backend.set_image_data_format('channels_last')\n",
    "\n",
    "# Define a labels array for future use\n",
    "labels = [\n",
    "        'Air Conditioner',\n",
    "        'Car Horn',\n",
    "        'Children Playing',\n",
    "        'Dog bark',\n",
    "        'Drilling',\n",
    "        'Engine Idling',\n",
    "        'Gun Shot',\n",
    "        'Jackhammer',\n",
    "        'Siren',\n",
    "        'Street Music'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "obvious-action",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Metadata\n",
    "metadata = pd.read_csv(metadata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "exempt-pound",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test split: 1746 \t\t Train split: 6986\n",
      "X test shape: (1746, 40, 174) \t X train shape: (6986, 40, 174)\n",
      "y test shape: (1746,) \t\t y train shape: (6986,)\n"
     ]
    }
   ],
   "source": [
    "indexes = []\n",
    "total = len(metadata)\n",
    "indexes = list(range(0, total))\n",
    "\n",
    "# Randomize indexes\n",
    "random.shuffle(indexes)\n",
    "\n",
    "# Divide the indexes into Train and Test\n",
    "test_split_pct = 20\n",
    "split_offset = math.floor(test_split_pct * total / 100)\n",
    "\n",
    "# Split the metadata\n",
    "test_split_idx = indexes[0:split_offset]\n",
    "train_split_idx = indexes[split_offset:total]\n",
    "\n",
    "\n",
    "# Split the features with the same indexes\n",
    "X_test = np.take(X, test_split_idx, axis=0)\n",
    "y_test = np.take(y, test_split_idx, axis=0)\n",
    "X_train = np.take(X, train_split_idx, axis=0)\n",
    "y_train = np.take(y, train_split_idx, axis=0)\n",
    "\n",
    "# Also split metadata\n",
    "test_meta = metadata.iloc[test_split_idx]\n",
    "train_meta = metadata.iloc[train_split_idx]\n",
    "\n",
    "# Print status\n",
    "print(\"Test split: {} \\t\\t Train split: {}\".format(len(test_meta), len(train_meta)))\n",
    "print(\"X test shape: {} \\t X train shape: {}\".format(X_test.shape, X_train.shape))\n",
    "print(\"y test shape: {} \\t\\t y train shape: {}\".format(y_test.shape, y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "significant-ontario",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_test_encoded = to_categorical(le.fit_transform(y_test))\n",
    "y_train_encoded = to_categorical(le.fit_transform(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "wired-youth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How data should be structured\n",
    "num_rows = 40\n",
    "num_columns = 174 \n",
    "num_channels = 1\n",
    "\n",
    "# Reshape to fit the network input (channel last)\n",
    "X_train = X_train.reshape(X_train.shape[0], num_rows, num_columns, num_channels)\n",
    "X_test = X_test.reshape(X_test.shape[0], num_rows, num_columns, num_channels)\n",
    "\n",
    "# Total number of labels to predict (equal to the network output nodes)\n",
    "num_labels = y_train_encoded.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "economic-xerox",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(spatial_dropout_rate_1=0, spatial_dropout_rate_2=0, l2_rate=0):\n",
    "\n",
    "    # Create a secquential object\n",
    "    model = Sequential()\n",
    "\n",
    "\n",
    "    # Conv 1\n",
    "    model.add(Conv2D(filters=32, \n",
    "                     kernel_size=(3, 3), \n",
    "                     kernel_regularizer=l2(l2_rate), \n",
    "                     input_shape=(num_rows, num_columns, num_channels)))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(SpatialDropout2D(spatial_dropout_rate_1))\n",
    "    model.add(Conv2D(filters=32, \n",
    "                     kernel_size=(3, 3), \n",
    "                     kernel_regularizer=l2(l2_rate)))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "    # Max Pooling #1\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(SpatialDropout2D(spatial_dropout_rate_1))\n",
    "    model.add(Conv2D(filters=64, \n",
    "                     kernel_size=(3, 3), \n",
    "                     kernel_regularizer=l2(l2_rate)))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(SpatialDropout2D(spatial_dropout_rate_2))\n",
    "    model.add(Conv2D(filters=64, \n",
    "                     kernel_size=(3,3), \n",
    "                     kernel_regularizer=l2(l2_rate)))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "   \n",
    "    # Reduces each h×w feature map to a single number by taking the average of all h,w values.\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "\n",
    "\n",
    "    # Softmax output\n",
    "    model.add(Dense(num_labels, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Regularization rates\n",
    "spatial_dropout_rate_1 = 0.07\n",
    "spatial_dropout_rate_2 = 0.14\n",
    "l2_rate = 0.0005\n",
    "\n",
    "model = create_model(spatial_dropout_rate_1, spatial_dropout_rate_2, l2_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "boring-translator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 38, 172, 32)       320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 38, 172, 32)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 38, 172, 32)       128       \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_1 (Spatial (None, 38, 172, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 36, 170, 32)       9248      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 36, 170, 32)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 36, 170, 32)       128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 18, 85, 32)        0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_2 (Spatial (None, 18, 85, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 83, 64)        18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 16, 83, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 83, 64)        256       \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_3 (Spatial (None, 16, 83, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 81, 64)        36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 14, 81, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 14, 81, 64)        256       \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 66,410\n",
      "Trainable params: 66,026\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "adam = Adam(lr=1e-4, beta_1=0.99, beta_2=0.999)\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy'], \n",
    "    optimizer=adam)\n",
    "\n",
    "# Display model architecture summary \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-papua",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "num_batch_size = 128\n",
    "model_file = 'simple-train-nb3.hdf5'\n",
    "model_path = os.path.join(models_path, model_file)\n",
    "\n",
    "\n",
    "# Save checkpoints\n",
    "checkpointer = ModelCheckpoint(filepath=model_path, \n",
    "                               verbose=1, \n",
    "                               save_best_only=True)\n",
    "start = datetime.now()\n",
    "history = model.fit(X_train, \n",
    "                    y_train_encoded, \n",
    "                    batch_size=num_batch_size, \n",
    "                    epochs=num_epochs, \n",
    "                    validation_split=1/12.,\n",
    "                    callbacks=[checkpointer], \n",
    "                    verbose=1)\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-experiment",
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.plot_train_history(history, x_ticks_vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-diesel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities for test set\n",
    "y_probs = model.predict(X_test, verbose=0)\n",
    "\n",
    "# Get predicted labels\n",
    "yhat_probs = np.argmax(y_probs, axis=1)\n",
    "y_trues = np.argmax(y_test_encoded, axis=1)\n",
    "\n",
    "# Add \"pred\" column\n",
    "test_meta['pred'] = yhat_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-prime",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-adaptation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-section",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "former-terrorism",
   "metadata": {},
   "source": [
    "# go through 45 combinations of experiments\n",
    "res = {}\n",
    "for class1 in range(10):\n",
    "    for class2 in range(class1 + 1, 10):\n",
    "\n",
    "        # accuracy vs num training samples (naive_rf)\n",
    "        naive_rf_acc_vs_n = list()\n",
    "        fraction_of_train_samples_space = np.geomspace(0.01, 1, num=8)\n",
    "        for fraction_of_train_samples in fraction_of_train_samples_space:\n",
    "            RF = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "            best_accuracy = np.mean(\n",
    "                [\n",
    "                    ConvRF.run_rf(\n",
    "                        RF,\n",
    "                        cifar_train_images,\n",
    "                        cifar_train_labels,\n",
    "                        cifar_test_images,\n",
    "                        cifar_test_labels,\n",
    "                        fraction_of_train_samples,\n",
    "                        class1,\n",
    "                        class2,\n",
    "                    )\n",
    "                    for _ in range(5)\n",
    "                ]\n",
    "            )\n",
    "            naive_rf_acc_vs_n.append(best_accuracy)\n",
    "\n",
    "        # accuracy vs num training samples (naive_rf)\n",
    "        conv_rf_2_layer = list()\n",
    "        for fraction_of_train_samples in fraction_of_train_samples_space:\n",
    "            conv_rf_2l = ConvRF.ConvRFClassifier(\n",
    "                layers=2, kernel_size=(10, 5), stride=(2, 1)\n",
    "            )\n",
    "            best_accuracy = np.mean(\n",
    "                [\n",
    "                    ConvRF.run_rf(\n",
    "                        conv_rf_2l,\n",
    "                        cifar_train_images,\n",
    "                        cifar_train_labels,\n",
    "                        cifar_test_images,\n",
    "                        cifar_test_labels,\n",
    "                        fraction_of_train_samples,\n",
    "                        class1,\n",
    "                        class2,\n",
    "                    )\n",
    "                    for _ in range(5)\n",
    "                ]\n",
    "            )\n",
    "            conv_rf_2_layer.append(best_accuracy)\n",
    "\n",
    "        # accuracy vs num training samples (naive_rf)\n",
    "        conv_rf_apply = list()\n",
    "        for fraction_of_train_samples in fraction_of_train_samples_space:\n",
    "            conv_rf_a = ConvRF.ConvRFClassifier(\n",
    "                layers=1, kernel_size=(10,), stride=(2,)\n",
    "            )\n",
    "            best_accuracy = np.mean(\n",
    "                [\n",
    "                    ConvRF.run_rf(\n",
    "                        conv_rf_a,\n",
    "                        cifar_train_images,\n",
    "                        cifar_train_labels,\n",
    "                        cifar_test_images,\n",
    "                        cifar_test_labels,\n",
    "                        fraction_of_train_samples,\n",
    "                        class1,\n",
    "                        class2,\n",
    "                    )\n",
    "                    for _ in range(5)\n",
    "                ]\n",
    "            )\n",
    "            conv_rf_apply.append(best_accuracy)\n",
    "\n",
    "        # accuracy vs num training samples (one layer cnn (32 filters))\n",
    "        cnn32_acc_vs_n = list()\n",
    "        for fraction_of_train_samples in fraction_of_train_samples_space:\n",
    "            best_accuracy = np.mean(\n",
    "                [\n",
    "                    ConvRF.run_cnn(\n",
    "                        SimpleCNN32Filter,\n",
    "                        cifar_train_images,\n",
    "                        cifar_train_labels,\n",
    "                        cifar_test_images,\n",
    "                        cifar_test_labels,\n",
    "                        fraction_of_train_samples,\n",
    "                        class1,\n",
    "                        class2,\n",
    "                        trainset,\n",
    "                        testset,\n",
    "                    )\n",
    "                    for _ in range(5)\n",
    "                ]\n",
    "            )\n",
    "            cnn32_acc_vs_n.append(best_accuracy)\n",
    "\n",
    "        # accuracy vs num training samples (two layer cnn (32 filters))\n",
    "        cnn32_two_layer_acc_vs_n = list()\n",
    "        for fraction_of_train_samples in fraction_of_train_samples_space:\n",
    "            best_accuracy = np.mean(\n",
    "                [\n",
    "                    ConvRF.run_cnn(\n",
    "                        SimpleCNN32Filter2Layers,\n",
    "                        cifar_train_images,\n",
    "                        cifar_train_labels,\n",
    "                        cifar_test_images,\n",
    "                        cifar_test_labels,\n",
    "                        fraction_of_train_samples,\n",
    "                        class1,\n",
    "                        class2,\n",
    "                        trainset,\n",
    "                        testset,\n",
    "                    )\n",
    "                    for _ in range(5)\n",
    "                ]\n",
    "            )\n",
    "            cnn32_two_layer_acc_vs_n.append(best_accuracy)\n",
    "\n",
    "        # accuracy vs num training samples (one layer cnn)\n",
    "        cnn_acc_vs_n = list()\n",
    "        for fraction_of_train_samples in fraction_of_train_samples_space:\n",
    "            best_accuracy = np.mean(\n",
    "                [\n",
    "                    ConvRF.run_cnn(\n",
    "                        SimpleCNNOneFilter,\n",
    "                        cifar_train_images,\n",
    "                        cifar_train_labels,\n",
    "                        cifar_test_images,\n",
    "                        cifar_test_labels,\n",
    "                        fraction_of_train_samples,\n",
    "                        class1,\n",
    "                        class2,\n",
    "                        trainset,\n",
    "                        testset,\n",
    "                    )\n",
    "                    for _ in range(5)\n",
    "                ]\n",
    "            )\n",
    "            cnn_acc_vs_n.append(best_accuracy)\n",
    "\n",
    "        table = pd.DataFrame(\n",
    "            np.concatenate(\n",
    "                (\n",
    "                    [naive_rf_acc_vs_n],\n",
    "                    [conv_rf_apply],\n",
    "                    [conv_rf_2_layer],\n",
    "                    [cnn_acc_vs_n],\n",
    "                    [cnn32_acc_vs_n],\n",
    "                    [cnn32_two_layer_acc_vs_n],\n",
    "                ),\n",
    "                axis=0,\n",
    "            )\n",
    "        )\n",
    "        algos = [\n",
    "            \"naiveRF\",\n",
    "            \"convrf\",\n",
    "            \"convrf2layer\",\n",
    "            \"simplecnn\",\n",
    "            \"cnn32\",\n",
    "            \"cnn32_2layer\",\n",
    "        ]\n",
    "        table[\"algos\"] = algos\n",
    "        cols = table.columns.tolist()\n",
    "        cols = [cols[-1]] + cols[:-1]\n",
    "        cols = pd.Index(cols)\n",
    "        table = table[cols]\n",
    "        res[str(class1) + \"_vs_\" + str(class2)] = table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
